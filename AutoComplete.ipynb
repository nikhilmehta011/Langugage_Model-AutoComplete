{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoComplete System -- Predict the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from N_Gram_Language_Model import (tokenized_sentences, count_n_grams, estimate_probabilities, \n",
    "                      get_words_with_nplus_frequency, count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating vocabulary with word occuring atleast twice\n",
    "vocab = get_words_with_nplus_frequency(tokenized_sentences, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get single word suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_a_word(previous_tokens, n_gram_counts, n_plus1_gram_counts, vocabulary, k=1.0, start_with=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get suggestion for the next word\n",
    "    \n",
    "    previous_tokens: The sentence you input where each token is a word. Must have length > n \n",
    "    n_gram_counts: Dictionary of counts of (n+1)-grams\n",
    "    n_plus1_gram_counts: Dictionary of counts of (n+1)-grams\n",
    "    vocabulary: List of words\n",
    "    k: positive constant, smoothing parameter\n",
    "    start_with: If not None, specifies the first few letters of the next word\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # length of previous words\n",
    "    n = len(list(n_gram_counts.keys())[0]) \n",
    "    \n",
    "    # get the most recent 'n' words as the previous n-gram\n",
    "    previous_n_gram = previous_tokens[-n:]\n",
    "\n",
    "    # Estimate the probabilities that each word in the vocabulary\n",
    "    # is the next word,\n",
    "    # given the previous n-gram, the dictionary of n-gram counts,\n",
    "    # the dictionary of n plus 1 gram counts, and the smoothing constant\n",
    "    probabilities = estimate_probabilities(previous_n_gram,\n",
    "                                           n_gram_counts, n_plus1_gram_counts,\n",
    "                                           vocabulary, k=k)\n",
    "    \n",
    "    # Initialize suggested word to None\n",
    "    # This will be set to the word with highest probability\n",
    "    suggestion = 'a'\n",
    "    \n",
    "    # Initialize the highest word probability to 0\n",
    "    # this will be set to the highest probability \n",
    "    # of all words to be suggested\n",
    "    max_prob = 0\n",
    "    \n",
    "    \n",
    "    # For each word and its probability in the probabilities dictionary:\n",
    "    for word, prob in probabilities.items(): \n",
    "        \n",
    "        # If the optional start_with string is set\n",
    "        if start_with != None:\n",
    "            \n",
    "            # Check if the beginning of word does not match with the letters in 'start_with'\n",
    "            if not word.startswith(start_with):\n",
    "\n",
    "                # if they don't match, skip this word (move onto the next word)\n",
    "                continue \n",
    "        \n",
    "        # Check if this word's probability\n",
    "        # is greater than the current maximum probability\n",
    "        if prob > max_prob:\n",
    "            \n",
    "            # If so, save this word as the best suggestion (so far)\n",
    "            suggestion = word\n",
    "            \n",
    "            # Save the new maximum probability\n",
    "            max_prob = prob\n",
    "    \n",
    "    return suggestion, max_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for single word suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_counts = count_n_grams(tokenized_sentences, 2)\n",
    "tri_counts = count_n_grams(tokenized_sentences, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_tokens = ['hello','how','are']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('you', 0.0007144132880871584)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_a_word(previous_tokens,bi_counts,tri_counts,vocab,k=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Suggestions on the basis of multiple N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=None):\n",
    "    \n",
    "    model_counts = len(n_gram_counts_list)\n",
    "    suggestions = []\n",
    "    \n",
    "    for i in range(model_counts-1):\n",
    "        n_gram_counts = n_gram_counts_list[i]\n",
    "        n_plus1_gram_counts = n_gram_counts_list[i+1]\n",
    "        \n",
    "        suggestion = suggest_a_word(previous_tokens, n_gram_counts,\n",
    "                                    n_plus1_gram_counts, vocabulary,\n",
    "                                    k=k, start_with=start_with)\n",
    "        suggestions.append(suggestion)\n",
    "    \n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing n-gram counts with n = 2 ...\n",
      "Computing n-gram counts with n = 3 ...\n",
      "Computing n-gram counts with n = 4 ...\n",
      "Computing n-gram counts with n = 5 ...\n"
     ]
    }
   ],
   "source": [
    "n_gram_counts_list = []\n",
    "\n",
    "for n in range(2, 6):\n",
    "    print(\"Computing n-gram counts with n =\", n, \"...\")\n",
    "    n_model_counts = count_n_grams(tokenized_sentences, n)\n",
    "    n_gram_counts_list.append(n_model_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for multiple N-Grams model suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_tokens = ['hello','where','are','you'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('going', 0.0009766781105718006),\n",
       " ('from', 0.00011918951132300358),\n",
       " ('oge', 1.4903795996840395e-05)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_suggestions(previous_tokens,n_gram_counts_list,vocab,k=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
